{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "progressive-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "victorian-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "alternative-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data of brain MRI and corresponding mask\n",
    "df_brain = pd.read_csv('data_mask.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "proper-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data in mask column to string format, to use categorical mode in flow_from_dataframe\n",
    "df_brain['mask'] = df_brain['mask'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dynamic-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_brain, test_size=0.15, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "surprised-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an image generator\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create a data generator which scales the data from 0 to 1 and make validation split\n",
    "datagen = ImageDataGenerator(rescale=1./255., \n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "curious-climb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2839 validated image filenames belonging to 2 classes.\n",
      "Found 500 validated image filenames belonging to 2 classes.\n",
      "Found 590 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "                    dataframe=train,\n",
    "                    directory='C:/Users/Victiny/Python_Project/Data_brain_tumor/',\n",
    "                    x_col='image_path',\n",
    "                    y_col='mask',\n",
    "                    subset='training',\n",
    "                    batch_size=16,\n",
    "                    shuffle=True, # shuffle the data so the order is not used as information for training\n",
    "                    class_mode='categorical',\n",
    "                    target_size=(256,256))\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "                    dataframe=train,\n",
    "                    directory='C:/Users/Victiny/Python_Project/Data_brain_tumor/',\n",
    "                    x_col='image_path',\n",
    "                    y_col='mask',\n",
    "                    subset='validation',\n",
    "                    batch_size=16,\n",
    "                    shuffle=True,\n",
    "                    class_mode='categorical',\n",
    "                    target_size=(256,256))\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "                    dataframe=test,\n",
    "                    directory='C:/Users/Victiny/Python_Project/Data_brain_tumor/',\n",
    "                    x_col='image_path',\n",
    "                    y_col='mask',\n",
    "                    batch_size=16,\n",
    "                    shuffle=False, # no need to shuffle the test data as we don't use it for training\n",
    "                    class_mode='categorical',\n",
    "                    target_size=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "filled-shoulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 85, 85, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               14450944  \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 14,452,354\n",
      "Trainable params: 14,452,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "# Convolutiom\n",
    "model.add(Conv2D(32, 3, 3, input_shape=(256, 256, 3), activation='relu'))\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "nonprofit-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "#define callbacks\n",
    "earlystopping = EarlyStopping(monitor = 'val_loss', mode = 'min', patience=10, restore_best_weights=True)\n",
    "\n",
    "# save the best model with least validation loss\n",
    "checkpointer = ModelCheckpoint(filepath='classifier_resnet_weights_cnn.hdf5', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "charming-hampton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 177 steps, validate for 31 steps\n",
      "Epoch 1/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.5288 - accuracy: 0.7421\n",
      "Epoch 00001: val_loss improved from inf to 0.49186, saving model to classifier_resnet_weights_nn.hdf5\n",
      "177/177 [==============================] - 60s 337ms/step - loss: 0.5286 - accuracy: 0.7421 - val_loss: 0.4919 - val_accuracy: 0.7681\n",
      "Epoch 2/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.4355 - accuracy: 0.7834\n",
      "Epoch 00002: val_loss improved from 0.49186 to 0.37742, saving model to classifier_resnet_weights_nn.hdf5\n",
      "177/177 [==============================] - 59s 331ms/step - loss: 0.4354 - accuracy: 0.7832 - val_loss: 0.3774 - val_accuracy: 0.7984\n",
      "Epoch 3/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.3901 - accuracy: 0.8044\n",
      "Epoch 00003: val_loss improved from 0.37742 to 0.36008, saving model to classifier_resnet_weights_nn.hdf5\n",
      "177/177 [==============================] - 59s 332ms/step - loss: 0.3903 - accuracy: 0.8034 - val_loss: 0.3601 - val_accuracy: 0.8145\n",
      "Epoch 4/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.3664 - accuracy: 0.8180\n",
      "Epoch 00004: val_loss did not improve from 0.36008\n",
      "177/177 [==============================] - 58s 325ms/step - loss: 0.3668 - accuracy: 0.8176 - val_loss: 0.3901 - val_accuracy: 0.7802\n",
      "Epoch 5/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.3465 - accuracy: 0.8408\n",
      "Epoch 00005: val_loss improved from 0.36008 to 0.33337, saving model to classifier_resnet_weights_nn.hdf5\n",
      "177/177 [==============================] - 59s 336ms/step - loss: 0.3467 - accuracy: 0.8406 - val_loss: 0.3334 - val_accuracy: 0.8367\n",
      "Epoch 6/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.3327 - accuracy: 0.8304 E\n",
      "Epoch 00006: val_loss improved from 0.33337 to 0.28662, saving model to classifier_resnet_weights_nn.hdf5\n",
      "177/177 [==============================] - 63s 357ms/step - loss: 0.3318 - accuracy: 0.8307 - val_loss: 0.2866 - val_accuracy: 0.8810\n",
      "Epoch 7/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.3111 - accuracy: 0.8568\n",
      "Epoch 00007: val_loss did not improve from 0.28662\n",
      "177/177 [==============================] - 57s 325ms/step - loss: 0.3103 - accuracy: 0.8576 - val_loss: 0.3180 - val_accuracy: 0.8569\n",
      "Epoch 8/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.3066 - accuracy: 0.8600\n",
      "Epoch 00008: val_loss did not improve from 0.28662\n",
      "177/177 [==============================] - 58s 325ms/step - loss: 0.3075 - accuracy: 0.8587 - val_loss: 0.3350 - val_accuracy: 0.8327\n",
      "Epoch 9/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.2802 - accuracy: 0.8725\n",
      "Epoch 00009: val_loss did not improve from 0.28662\n",
      "177/177 [==============================] - 58s 326ms/step - loss: 0.2809 - accuracy: 0.8718 - val_loss: 0.3132 - val_accuracy: 0.8569\n",
      "Epoch 10/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.2740 - accuracy: 0.8717\n",
      "Epoch 00010: val_loss did not improve from 0.28662\n",
      "177/177 [==============================] - 58s 326ms/step - loss: 0.2731 - accuracy: 0.8721 - val_loss: 0.2962 - val_accuracy: 0.8770\n",
      "Epoch 11/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.2762 - accuracy: 0.8789\n",
      "Epoch 00011: val_loss did not improve from 0.28662\n",
      "177/177 [==============================] - 58s 328ms/step - loss: 0.2758 - accuracy: 0.8789 - val_loss: 0.2962 - val_accuracy: 0.8790\n",
      "Epoch 12/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.2637 - accuracy: 0.8807\n",
      "Epoch 00012: val_loss improved from 0.28662 to 0.26393, saving model to classifier_resnet_weights_nn.hdf5\n",
      "177/177 [==============================] - 59s 332ms/step - loss: 0.2642 - accuracy: 0.8799 - val_loss: 0.2639 - val_accuracy: 0.9032\n",
      "Epoch 13/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.2520 - accuracy: 0.8928\n",
      "Epoch 00013: val_loss did not improve from 0.26393\n",
      "177/177 [==============================] - 58s 328ms/step - loss: 0.2513 - accuracy: 0.8930 - val_loss: 0.3026 - val_accuracy: 0.8891\n",
      "Epoch 14/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.2455 - accuracy: 0.8885\n",
      "Epoch 00014: val_loss did not improve from 0.26393\n",
      "177/177 [==============================] - 58s 327ms/step - loss: 0.2449 - accuracy: 0.8884 - val_loss: 0.3133 - val_accuracy: 0.8851\n",
      "Epoch 15/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.2297 - accuracy: 0.9038\n",
      "Epoch 00015: val_loss did not improve from 0.26393\n",
      "177/177 [==============================] - 58s 327ms/step - loss: 0.2331 - accuracy: 0.9026 - val_loss: 0.2793 - val_accuracy: 0.8952\n",
      "Epoch 16/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.2294 - accuracy: 0.9027\n",
      "Epoch 00016: val_loss did not improve from 0.26393\n",
      "177/177 [==============================] - 58s 326ms/step - loss: 0.2299 - accuracy: 0.9022 - val_loss: 0.2706 - val_accuracy: 0.8931\n",
      "Epoch 17/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.2260 - accuracy: 0.9081\n",
      "Epoch 00017: val_loss did not improve from 0.26393\n",
      "177/177 [==============================] - 58s 327ms/step - loss: 0.2267 - accuracy: 0.9072 - val_loss: 0.2651 - val_accuracy: 0.8952\n",
      "Epoch 18/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9077\n",
      "Epoch 00018: val_loss did not improve from 0.26393\n",
      "177/177 [==============================] - 57s 323ms/step - loss: 0.2168 - accuracy: 0.9079 - val_loss: 0.3006 - val_accuracy: 0.8891\n",
      "Epoch 19/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.2143 - accuracy: 0.9067\n",
      "Epoch 00019: val_loss improved from 0.26393 to 0.23684, saving model to classifier_resnet_weights_nn.hdf5\n",
      "177/177 [==============================] - 59s 332ms/step - loss: 0.2141 - accuracy: 0.9068 - val_loss: 0.2368 - val_accuracy: 0.9032\n",
      "Epoch 20/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.2023 - accuracy: 0.9127\n",
      "Epoch 00020: val_loss improved from 0.23684 to 0.23523, saving model to classifier_resnet_weights_nn.hdf5\n",
      "177/177 [==============================] - 59s 331ms/step - loss: 0.2023 - accuracy: 0.9132 - val_loss: 0.2352 - val_accuracy: 0.9194\n",
      "Epoch 21/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1917 - accuracy: 0.9230\n",
      "Epoch 00021: val_loss did not improve from 0.23523\n",
      "177/177 [==============================] - 58s 329ms/step - loss: 0.1919 - accuracy: 0.9228 - val_loss: 0.2952 - val_accuracy: 0.8952\n",
      "Epoch 22/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1909 - accuracy: 0.9202\n",
      "Epoch 00022: val_loss did not improve from 0.23523\n",
      "177/177 [==============================] - 58s 327ms/step - loss: 0.1901 - accuracy: 0.9207 - val_loss: 0.2854 - val_accuracy: 0.8911\n",
      "Epoch 23/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1909 - accuracy: 0.9138\n",
      "Epoch 00023: val_loss did not improve from 0.23523\n",
      "177/177 [==============================] - 58s 328ms/step - loss: 0.1902 - accuracy: 0.9143 - val_loss: 0.2783 - val_accuracy: 0.9073\n",
      "Epoch 24/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1840 - accuracy: 0.9284\n",
      "Epoch 00024: val_loss did not improve from 0.23523\n",
      "177/177 [==============================] - 58s 325ms/step - loss: 0.1835 - accuracy: 0.9288 - val_loss: 0.2765 - val_accuracy: 0.8972\n",
      "Epoch 25/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1793 - accuracy: 0.9241 ETA: 3s - loss: 0\n",
      "Epoch 00025: val_loss did not improve from 0.23523\n",
      "177/177 [==============================] - 58s 327ms/step - loss: 0.1807 - accuracy: 0.9238 - val_loss: 0.2719 - val_accuracy: 0.9073\n",
      "Epoch 26/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.9252\n",
      "Epoch 00026: val_loss did not improve from 0.23523\n",
      "177/177 [==============================] - 58s 329ms/step - loss: 0.1734 - accuracy: 0.9256 - val_loss: 0.2699 - val_accuracy: 0.9113\n",
      "Epoch 27/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1735 - accuracy: 0.9252\n",
      "Epoch 00027: val_loss did not improve from 0.23523\n",
      "177/177 [==============================] - 58s 326ms/step - loss: 0.1749 - accuracy: 0.9245 - val_loss: 0.2409 - val_accuracy: 0.9234\n",
      "Epoch 28/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9384\n",
      "Epoch 00028: val_loss did not improve from 0.23523\n",
      "177/177 [==============================] - 58s 326ms/step - loss: 0.1611 - accuracy: 0.9377 - val_loss: 0.2827 - val_accuracy: 0.8911\n",
      "Epoch 29/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.9412\n",
      "Epoch 00029: val_loss did not improve from 0.23523\n",
      "177/177 [==============================] - 58s 326ms/step - loss: 0.1541 - accuracy: 0.9416 - val_loss: 0.2858 - val_accuracy: 0.9113\n",
      "Epoch 30/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1523 - accuracy: 0.9398\n",
      "Epoch 00030: val_loss improved from 0.23523 to 0.23197, saving model to classifier_resnet_weights_nn.hdf5\n",
      "177/177 [==============================] - 59s 332ms/step - loss: 0.1531 - accuracy: 0.9391 - val_loss: 0.2320 - val_accuracy: 0.9113\n",
      "Epoch 31/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1703 - accuracy: 0.9305\n",
      "Epoch 00031: val_loss did not improve from 0.23197\n",
      "177/177 [==============================] - 58s 328ms/step - loss: 0.1704 - accuracy: 0.9302 - val_loss: 0.2766 - val_accuracy: 0.9254\n",
      "Epoch 32/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1569 - accuracy: 0.9384\n",
      "Epoch 00032: val_loss did not improve from 0.23197\n",
      "177/177 [==============================] - 58s 327ms/step - loss: 0.1569 - accuracy: 0.9384 - val_loss: 0.2637 - val_accuracy: 0.8992\n",
      "Epoch 33/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1516 - accuracy: 0.9377\n",
      "Epoch 00033: val_loss did not improve from 0.23197\n",
      "177/177 [==============================] - 58s 326ms/step - loss: 0.1537 - accuracy: 0.9366 - val_loss: 0.2460 - val_accuracy: 0.9093\n",
      "Epoch 34/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1487 - accuracy: 0.9359\n",
      "Epoch 00034: val_loss did not improve from 0.23197\n",
      "177/177 [==============================] - 58s 327ms/step - loss: 0.1481 - accuracy: 0.9362 - val_loss: 0.2905 - val_accuracy: 0.9274\n",
      "Epoch 35/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1425 - accuracy: 0.9458\n",
      "Epoch 00035: val_loss did not improve from 0.23197\n",
      "177/177 [==============================] - 58s 325ms/step - loss: 0.1427 - accuracy: 0.9458 - val_loss: 0.2608 - val_accuracy: 0.9153\n",
      "Epoch 36/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1366 - accuracy: 0.9480 ETA: 5s -\n",
      "Epoch 00036: val_loss did not improve from 0.23197\n",
      "177/177 [==============================] - 58s 329ms/step - loss: 0.1362 - accuracy: 0.9479 - val_loss: 0.2796 - val_accuracy: 0.9153\n",
      "Epoch 37/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9462\n",
      "Epoch 00037: val_loss did not improve from 0.23197\n",
      "177/177 [==============================] - 58s 329ms/step - loss: 0.1463 - accuracy: 0.9458 - val_loss: 0.2773 - val_accuracy: 0.9254\n",
      "Epoch 38/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1354 - accuracy: 0.9501\n",
      "Epoch 00038: val_loss did not improve from 0.23197\n",
      "177/177 [==============================] - 58s 328ms/step - loss: 0.1362 - accuracy: 0.9497 - val_loss: 0.2772 - val_accuracy: 0.9073\n",
      "Epoch 39/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.9466\n",
      "Epoch 00039: val_loss did not improve from 0.23197\n",
      "177/177 [==============================] - 58s 328ms/step - loss: 0.1286 - accuracy: 0.9469 - val_loss: 0.3225 - val_accuracy: 0.9032\n",
      "Epoch 40/100\n",
      "176/177 [============================>.] - ETA: 0s - loss: 0.1290 - accuracy: 0.9487\n",
      "Epoch 00040: val_loss did not improve from 0.23197\n",
      "177/177 [==============================] - 58s 327ms/step - loss: 0.1291 - accuracy: 0.9486 - val_loss: 0.2426 - val_accuracy: 0.9294\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    steps_per_epoch=train_generator.n//16,\n",
    "                    epochs=100,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.n//16,\n",
    "                    callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "applicable-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classifier_resnet_weights_cnn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "imperial-error",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 3s 74ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 2.7831680e-08],\n",
       "       [3.7984666e-03, 9.9620157e-01],\n",
       "       [3.9889098e-08, 1.0000000e+00],\n",
       "       ...,\n",
       "       [1.0000000e+00, 6.7971605e-13],\n",
       "       [9.9921370e-01, 7.8628946e-04],\n",
       "       [9.8339578e-06, 9.9999022e-01]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction\n",
    "test_predict = model.predict(test_generator, #steps=test_generator.n//16, \n",
    "                             verbose=1)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "weird-harvey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '1', '1', '0', '0', '1', '0', '1', '0'], dtype='<U1')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Model evaluation\"\"\"\n",
    "# obtain the predicted class from model prediction (probability)\n",
    "y_predict = []\n",
    "for i in test_predict:\n",
    "    y_predict.append(str(np.argmax(i)))\n",
    "y_predict = np.asarray(y_predict)\n",
    "y_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "three-forge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '1', '1', '0', '0', '1', '0', '1', '0'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.asarray(test['mask'])[:len(test_predict)]\n",
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "grand-minority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       381\n",
      "           1       0.92      0.84      0.88       209\n",
      "\n",
      "    accuracy                           0.92       590\n",
      "   macro avg       0.92      0.90      0.91       590\n",
      "weighted avg       0.92      0.92      0.92       590\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print('%.4f'%accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
