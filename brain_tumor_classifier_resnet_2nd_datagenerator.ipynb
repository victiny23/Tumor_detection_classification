{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "polish-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import cv2\n",
    "from skimage import io # pip install scikit-image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "# from google.colab import files\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adjusted-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ResNet50 base model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(256,256,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "micro-engineer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw = np.array(base_model.weights)\n",
    "mw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "entire-front",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'conv5_block3_3_bn/moving_variance:0' shape=(2048,) dtype=float32, numpy=\n",
       "array([0.0099396 , 0.00943395, 0.01045332, ..., 0.00850692, 0.01214169,\n",
       "       0.00997391], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "written-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brain = pd.read_csv('data_mask.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "liquid-database",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA_CS_5395_19981004</td>\n",
       "      <td>TCGA_CS_5395_19981004/TCGA_CS_5395_19981004_1.tif</td>\n",
       "      <td>TCGA_CS_5395_19981004/TCGA_CS_5395_19981004_1_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA_CS_5395_19981004</td>\n",
       "      <td>TCGA_CS_4944_20010208/TCGA_CS_4944_20010208_1.tif</td>\n",
       "      <td>TCGA_CS_4944_20010208/TCGA_CS_4944_20010208_1_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA_CS_5395_19981004</td>\n",
       "      <td>TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_1.tif</td>\n",
       "      <td>TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_1_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA_CS_5395_19981004</td>\n",
       "      <td>TCGA_CS_4943_20000902/TCGA_CS_4943_20000902_1.tif</td>\n",
       "      <td>TCGA_CS_4943_20000902/TCGA_CS_4943_20000902_1_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA_CS_5395_19981004</td>\n",
       "      <td>TCGA_CS_5396_20010302/TCGA_CS_5396_20010302_1.tif</td>\n",
       "      <td>TCGA_CS_5396_20010302/TCGA_CS_5396_20010302_1_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              patient_id                                         image_path  \\\n",
       "0  TCGA_CS_5395_19981004  TCGA_CS_5395_19981004/TCGA_CS_5395_19981004_1.tif   \n",
       "1  TCGA_CS_5395_19981004  TCGA_CS_4944_20010208/TCGA_CS_4944_20010208_1.tif   \n",
       "2  TCGA_CS_5395_19981004  TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_1.tif   \n",
       "3  TCGA_CS_5395_19981004  TCGA_CS_4943_20000902/TCGA_CS_4943_20000902_1.tif   \n",
       "4  TCGA_CS_5395_19981004  TCGA_CS_5396_20010302/TCGA_CS_5396_20010302_1.tif   \n",
       "\n",
       "                                           mask_path  mask  \n",
       "0  TCGA_CS_5395_19981004/TCGA_CS_5395_19981004_1_...     0  \n",
       "1  TCGA_CS_4944_20010208/TCGA_CS_4944_20010208_1_...     0  \n",
       "2  TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_1_...     0  \n",
       "3  TCGA_CS_4943_20000902/TCGA_CS_4943_20000902_1_...     0  \n",
       "4  TCGA_CS_5396_20010302/TCGA_CS_5396_20010302_1_...     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_brain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "magnetic-russia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_brain['mask'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "numerical-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid = train_test_split(df_brain, test_size=0.2, random_state=12345)\n",
    "X_valid, X_test = train_test_split(X_valid, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "contrary-missouri",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854     0\n",
       "1628    0\n",
       "914     0\n",
       "1614    1\n",
       "1838    1\n",
       "       ..\n",
       "3492    0\n",
       "2177    1\n",
       "3357    0\n",
       "3557    1\n",
       "482     0\n",
       "Name: mask, Length: 3143, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "massive-control",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260     0\n",
       "2830    0\n",
       "478     0\n",
       "1480    0\n",
       "3510    1\n",
       "       ..\n",
       "3832    0\n",
       "2716    0\n",
       "2770    1\n",
       "3572    1\n",
       "3527    0\n",
       "Name: mask, Length: 393, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "retired-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = list(X_train.image_path)\n",
    "train_mask = list(X_train['mask'])\n",
    "\n",
    "valid_image = list(X_valid.image_path)\n",
    "valid_mask = list(X_valid['mask'])\n",
    "\n",
    "\n",
    "test_image = list(X_test.image_path)\n",
    "test_mask = list(X_test['mask'])\n",
    "\n",
    "from importlib import reload\n",
    "import utilities\n",
    "reload(utilities)\n",
    "from utilities import DataGeneratorClassify\n",
    "\n",
    "# create image generators\n",
    "train_generator = DataGeneratorClassify(train_image, train_mask)\n",
    "valid_generator = DataGeneratorClassify(valid_image, valid_mask)\n",
    "test_generator = DataGeneratorClassify(test_image, test_mask, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wicked-wiring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_generator.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mental-knitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(valid_generator.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fuzzy-stockholm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(valid_generator.mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "familiar-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add classification head to the base model\n",
    "head_model = base_model.output\n",
    "head_model = AveragePooling2D(pool_size=(4, 4))(head_model)\n",
    "head_model = Flatten()(head_model)\n",
    "head_model = Dense(256, activation='relu')(head_model)\n",
    "head_model = Dropout(0.3)(head_model)\n",
    "# head_model = Dense(256, activation='relu')(head_model)\n",
    "# head_model = Dropout(0.3)(head_model)\n",
    "# head_model = Dense(256, activation='relu')(head_model)\n",
    "# head_model = Dropout(0.3)(head_model)\n",
    "head_model = Dense(1, activation='sigmoid')(head_model)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=head_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "amateur-clear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 2, 2, 2048)   0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8192)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          2097408     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 25,685,377\n",
      "Trainable params: 25,632,257\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "concerned-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fifteen-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use early stopping to exit training if validation loss is not decreasing after certain epochs(patience)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "# save the best model with least validation loss\n",
    "checkpointer = ModelCheckpoint(filepath='classifier_resnet_weights_datagen2.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hourly-partner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 196 steps, validate for 24 steps\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 13s - loss: 0.3332 - accuracy: 0.8596\n",
      "Epoch 00001: val_loss improved from inf to 0.54324, saving model to classifier_resnet_weights_datagen2.hdf5\n",
      "196/196 [==============================] - 2719s 14s/step - loss: 0.3322 - accuracy: 0.8603 - val_loss: 0.5432 - val_accuracy: 0.7344\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 10s - loss: 0.1206 - accuracy: 0.9548\n",
      "Epoch 00002: val_loss improved from 0.54324 to 0.39074, saving model to classifier_resnet_weights_datagen2.hdf5\n",
      "196/196 [==============================] - 2131s 11s/step - loss: 0.1204 - accuracy: 0.9550 - val_loss: 0.3907 - val_accuracy: 0.8151\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 9s - loss: 0.0574 - accuracy: 0.9827 \n",
      "Epoch 00003: val_loss improved from 0.39074 to 0.36658, saving model to classifier_resnet_weights_datagen2.hdf5\n",
      "196/196 [==============================] - 1937s 10s/step - loss: 0.0572 - accuracy: 0.9828 - val_loss: 0.3666 - val_accuracy: 0.8724\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 9s - loss: 0.0760 - accuracy: 0.9772 \n",
      "Epoch 00004: val_loss improved from 0.36658 to 0.30724, saving model to classifier_resnet_weights_datagen2.hdf5\n",
      "196/196 [==============================] - 1974s 10s/step - loss: 0.0757 - accuracy: 0.9774 - val_loss: 0.3072 - val_accuracy: 0.9349\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 9s - loss: 0.0394 - accuracy: 0.9872 \n",
      "Epoch 00005: val_loss improved from 0.30724 to 0.11637, saving model to classifier_resnet_weights_datagen2.hdf5\n",
      "196/196 [==============================] - 1924s 10s/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.1164 - val_accuracy: 0.9688\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 9s - loss: 0.0351 - accuracy: 0.9910 \n",
      "Epoch 00006: val_loss did not improve from 0.11637\n",
      "196/196 [==============================] - 1928s 10s/step - loss: 0.0351 - accuracy: 0.9911 - val_loss: 0.2619 - val_accuracy: 0.9557\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 9s - loss: 0.0406 - accuracy: 0.9859 \n",
      "Epoch 00007: val_loss did not improve from 0.11637\n",
      "196/196 [==============================] - 1926s 10s/step - loss: 0.0404 - accuracy: 0.9860 - val_loss: 0.1462 - val_accuracy: 0.9583\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 9s - loss: 0.0115 - accuracy: 0.9968 \n",
      "Epoch 00008: val_loss did not improve from 0.11637\n",
      "196/196 [==============================] - 1924s 10s/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.1429 - val_accuracy: 0.9661\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 9s - loss: 0.0020 - accuracy: 0.9997 \n",
      "Epoch 00009: val_loss did not improve from 0.11637\n",
      "196/196 [==============================] - 1924s 10s/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.1453 - val_accuracy: 0.9688\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 9s - loss: 1.9279e-04 - accuracy: 1.0000 \n",
      "Epoch 00010: val_loss did not improve from 0.11637\n",
      "196/196 [==============================] - 1926s 10s/step - loss: 1.9186e-04 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9688\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    # steps_per_epoch=train_generator.n//16,\n",
    "                    epochs=100,\n",
    "                    validation_data=valid_generator,\n",
    "                    # validation_steps=valid_generator.n//16,\n",
    "                    callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "subsequent-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('classifier_resnet_model_datagen2.json', 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wicked-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model (instead of training the model for a long time)\n",
    "with open('classifier_resnet_model_datagen2.json', 'r') as json_file:\n",
    "    json_saved_model = json_file.read()\n",
    "# load the model\n",
    "model = tf.keras.models.model_from_json(json_saved_model)\n",
    "model.load_weights('classifier_resnet_weights_datagen2.hdf5')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "present-gathering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>TCGA_CS_6186_20000601</td>\n",
       "      <td>TCGA_DU_7301_19911112/TCGA_DU_7301_19911112_3.tif</td>\n",
       "      <td>TCGA_DU_7301_19911112/TCGA_DU_7301_19911112_3_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>TCGA_HT_7860_19960513</td>\n",
       "      <td>TCGA_HT_7879_19981009/TCGA_HT_7879_19981009_28...</td>\n",
       "      <td>TCGA_HT_7879_19981009/TCGA_HT_7879_19981009_28...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>TCGA_DU_5872_19950223</td>\n",
       "      <td>TCGA_DU_8162_19961029/TCGA_DU_8162_19961029_5.tif</td>\n",
       "      <td>TCGA_DU_8162_19961029/TCGA_DU_8162_19961029_5_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>TCGA_DU_7301_19911112</td>\n",
       "      <td>TCGA_FG_5962_20000626/TCGA_FG_5962_20000626_14...</td>\n",
       "      <td>TCGA_FG_5962_20000626/TCGA_FG_5962_20000626_14...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>TCGA_DU_8164_19970111</td>\n",
       "      <td>TCGA_DU_A5TT_19980318/TCGA_DU_A5TT_19980318_43...</td>\n",
       "      <td>TCGA_DU_A5TT_19980318/TCGA_DU_A5TT_19980318_43...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>TCGA_DU_5871_19941206</td>\n",
       "      <td>TCGA_HT_A61A_20000127/TCGA_HT_A61A_20000127_61...</td>\n",
       "      <td>TCGA_HT_A61A_20000127/TCGA_HT_A61A_20000127_61...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>TCGA_HT_7694_19950404</td>\n",
       "      <td>TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_27...</td>\n",
       "      <td>TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_27...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>TCGA_HT_7692_19960724</td>\n",
       "      <td>TCGA_DU_7010_19860307/TCGA_DU_7010_19860307_27...</td>\n",
       "      <td>TCGA_DU_7010_19860307/TCGA_DU_7010_19860307_27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3572</th>\n",
       "      <td>TCGA_DU_7300_19910814</td>\n",
       "      <td>TCGA_HT_A61B_19991127/TCGA_HT_A61B_19991127_45...</td>\n",
       "      <td>TCGA_HT_A61B_19991127/TCGA_HT_A61B_19991127_45...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>TCGA_DU_8168_19970503</td>\n",
       "      <td>TCGA_DU_6400_19830518/TCGA_DU_6400_19830518_44...</td>\n",
       "      <td>TCGA_DU_6400_19830518/TCGA_DU_6400_19830518_44...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 patient_id  \\\n",
       "260   TCGA_CS_6186_20000601   \n",
       "2830  TCGA_HT_7860_19960513   \n",
       "478   TCGA_DU_5872_19950223   \n",
       "1480  TCGA_DU_7301_19911112   \n",
       "3510  TCGA_DU_8164_19970111   \n",
       "...                     ...   \n",
       "3832  TCGA_DU_5871_19941206   \n",
       "2716  TCGA_HT_7694_19950404   \n",
       "2770  TCGA_HT_7692_19960724   \n",
       "3572  TCGA_DU_7300_19910814   \n",
       "3527  TCGA_DU_8168_19970503   \n",
       "\n",
       "                                             image_path  \\\n",
       "260   TCGA_DU_7301_19911112/TCGA_DU_7301_19911112_3.tif   \n",
       "2830  TCGA_HT_7879_19981009/TCGA_HT_7879_19981009_28...   \n",
       "478   TCGA_DU_8162_19961029/TCGA_DU_8162_19961029_5.tif   \n",
       "1480  TCGA_FG_5962_20000626/TCGA_FG_5962_20000626_14...   \n",
       "3510  TCGA_DU_A5TT_19980318/TCGA_DU_A5TT_19980318_43...   \n",
       "...                                                 ...   \n",
       "3832  TCGA_HT_A61A_20000127/TCGA_HT_A61A_20000127_61...   \n",
       "2716  TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_27...   \n",
       "2770  TCGA_DU_7010_19860307/TCGA_DU_7010_19860307_27...   \n",
       "3572  TCGA_HT_A61B_19991127/TCGA_HT_A61B_19991127_45...   \n",
       "3527  TCGA_DU_6400_19830518/TCGA_DU_6400_19830518_44...   \n",
       "\n",
       "                                              mask_path  mask  \n",
       "260   TCGA_DU_7301_19911112/TCGA_DU_7301_19911112_3_...     0  \n",
       "2830  TCGA_HT_7879_19981009/TCGA_HT_7879_19981009_28...     0  \n",
       "478   TCGA_DU_8162_19961029/TCGA_DU_8162_19961029_5_...     0  \n",
       "1480  TCGA_FG_5962_20000626/TCGA_FG_5962_20000626_14...     0  \n",
       "3510  TCGA_DU_A5TT_19980318/TCGA_DU_A5TT_19980318_43...     1  \n",
       "...                                                 ...   ...  \n",
       "3832  TCGA_HT_A61A_20000127/TCGA_HT_A61A_20000127_61...     0  \n",
       "2716  TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_27...     0  \n",
       "2770  TCGA_DU_7010_19860307/TCGA_DU_7010_19860307_27...     1  \n",
       "3572  TCGA_HT_A61B_19991127/TCGA_HT_A61B_19991127_45...     1  \n",
       "3527  TCGA_DU_6400_19830518/TCGA_DU_6400_19830518_44...     0  \n",
       "\n",
       "[393 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "forty-pakistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3167    0\n",
       "390     0\n",
       "2864    0\n",
       "3336    0\n",
       "919     1\n",
       "3202    0\n",
       "3793    0\n",
       "1530    1\n",
       "2440    1\n",
       "654     0\n",
       "Name: mask, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['mask'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "handmade-pendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 393 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# from keras_preprocessing.image import ImageDataGenerator\n",
    "# test_datagen = ImageDataGenerator(1./255.)\n",
    "# test_generator = test_datagen.flow_from_dataframe(\n",
    "#                     dataframe=X_valid,\n",
    "#                     directory='C:/Users/Victiny/Python_Project/Data_brain_tumor/',\n",
    "#                     x_col='image_path',\n",
    "#                     y_col='mask',\n",
    "#                     batch_size=16,\n",
    "#                     shuffle=False, # no need to shuffle the test data as we don't use it for training\n",
    "#                     class_mode='binary',\n",
    "#                     target_size=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "outdoor-boring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 67s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "test_predict = model.predict(test_generator, #steps=test_generator.n//16, \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "expected-fetish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1308661e-05],\n",
       "       [1.9192696e-05],\n",
       "       [8.1974161e-01],\n",
       "       [0.0000000e+00],\n",
       "       [9.9979579e-01],\n",
       "       [1.8239021e-05],\n",
       "       [3.4385920e-04],\n",
       "       [9.9394155e-01],\n",
       "       [9.9995917e-01],\n",
       "       [0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "departmental-exemption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 1, 0, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "y_predict = [int(np.rint(i)) for i in test_predict]\n",
    "y_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "opening-british",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "secure-hanging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.asarray(X_test['mask'])[:len(test_predict)]\n",
    "y_test = y_test.astype('int')\n",
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "indoor-saver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "inclusive-northwest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "forward-virgin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       262\n",
      "           1       0.97      0.93      0.95       122\n",
      "\n",
      "    accuracy                           0.97       384\n",
      "   macro avg       0.97      0.96      0.96       384\n",
      "weighted avg       0.97      0.97      0.97       384\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print('%.4f'%accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
